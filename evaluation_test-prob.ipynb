{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "142b03d5-8a0d-4650-a332-6bb440f816d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noeyiue/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "import os\n",
    "\n",
    "import shutil\n",
    "import warnings\n",
    "import platform\n",
    "from glob import glob\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from dataclasses import dataclass\n",
    " \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    " \n",
    "# Next, we have our usual torch and torchvision imports.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    " \n",
    "import torchvision\n",
    "import torchvision.transforms as TF\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.ops import sigmoid_focal_loss\n",
    " \n",
    "# Importing lighting along with a built-in callback it provides.\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import LearningRateMonitor, ModelCheckpoint, EarlyStopping\n",
    " \n",
    "# Importing torchmetrics modular and functional evaluation implementations.\n",
    "from torchmetrics import MeanMetric\n",
    "from torchmetrics.classification import MultilabelF1Score\n",
    "from torchmetrics.classification import MultilabelAccuracy\n",
    " \n",
    "# To print model summary.\n",
    "from torchinfo import summary\n",
    "\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53096690-470f-47a8-84ce-1b98f8dfb0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetConfig:\n",
    "    IMAGE_SIZE: tuple = (224, 224) # (W, H)\n",
    "    CHANNELS: int = 3\n",
    "    NUM_CLASSES: int = 59\n",
    "    VALID_PCT: float = 0.1\n",
    "\n",
    "    # Pre-defined Mean & Std. Dev. of the Imagenet Trained model\n",
    "    MEAN: tuple = (0.485, 0.456, 0.406)\n",
    "    STD: tuple = (0.229, 0.224, 0.225)\n",
    "\n",
    "    # dataset file and folder paths\n",
    "    IMG_DIR: str = \"/home/noeyiue/cpe/ICSEC/annotation/dataset\"\n",
    "\n",
    "class TrainingConfig:\n",
    "    BATCH_SIZE: int = 32\n",
    "    NUM_EPOCHS: int = 30\n",
    "    INIT_LR: float = 1e-4\n",
    "    NUM_WORKERS: int = os.cpu_count()\n",
    "    OPTIMIZER_NAME: str = \"Adam\"\n",
    "    WEIGHT_DECAY: float = 1e-4\n",
    "    USE_SCHEDULER: bool = True\n",
    "    SCHEDULER: str = \"multi_step_lr\"\n",
    "    METRIC_THRESH: float = 0.4\n",
    "    MODEL_NAME: str = \"mobilenet_v3_small\"\n",
    "    FREEZE_BACKBONE: bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1e6dd3b-222d-4511-99c8-797c2a72b1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UPARModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str,\n",
    "        num_classes: int = 59,\n",
    "        freeze_backbone: bool = False,\n",
    "        init_lr: float = 1e-4,\n",
    "        optimizer_name: str = \"Adam\",\n",
    "        weight_decay: float = 1e-4,\n",
    "        use_scheduler: bool = False,\n",
    "        f1_metric_threshold: float = 0.4,\n",
    "        metrics_file_path: str = \"metrics.json\",\n",
    "        dropout_prob: float = 0.3\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Save the arguments as hyperparameters.\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Loading model using the function defined above.\n",
    "        self.model = get_model(\n",
    "            model_name=self.hparams.model_name,\n",
    "            num_classes=self.hparams.num_classes,\n",
    "            freeze_backbone=self.hparams.freeze_backbone,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=self.hparams.dropout_prob)\n",
    "\n",
    "        # Initialize loss class.\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        # Initializing the required metric objects.\n",
    "        self.mean_train_loss = MeanMetric()\n",
    "        self.mean_train_f1 = MultilabelF1Score(num_labels=self.hparams.num_classes, \n",
    "                                               average=\"macro\", threshold=self.hparams.f1_metric_threshold)\n",
    "        self.train_mA = MultilabelAccuracy(num_labels=self.hparams.num_classes, \n",
    "                                               average=\"macro\", threshold=self.hparams.f1_metric_threshold)\n",
    "        self.mean_valid_loss = MeanMetric()\n",
    "        self.mean_valid_f1 = MultilabelF1Score(num_labels=self.hparams.num_classes, \n",
    "                                               average=\"macro\", threshold=self.hparams.f1_metric_threshold)\n",
    "        self.valid_mA = MultilabelAccuracy(num_labels=self.hparams.num_classes, \n",
    "                                               average=\"macro\", threshold=self.hparams.f1_metric_threshold)\n",
    "\n",
    "        self.metrics_file_path = metrics_file_path\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, *args, **kwargs):\n",
    "        data, target = batch\n",
    "        logits = self(data)\n",
    "        loss = self.loss_fn(logits, target)\n",
    "    \n",
    "        # Update metric states\n",
    "        self.mean_train_loss(loss, weight=data.shape[0])\n",
    "        self.mean_train_f1(logits, target)\n",
    "        self.train_mA(logits, target)\n",
    "    \n",
    "        # Log metrics\n",
    "        self.log(\"train/batch_loss\", self.mean_train_loss, prog_bar=True)\n",
    "        self.log(\"train/batch_f1\", self.mean_train_f1, prog_bar=True)\n",
    "        self.log(\"train/batch_mA\", self.train_mA, prog_bar=True)\n",
    "    \n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        # Computing and logging the training mean loss & mean f1.\n",
    "        self.log(\"train/loss\", self.mean_train_loss, prog_bar=True)\n",
    "        self.log(\"train/f1\", self.mean_train_f1, prog_bar=True)\n",
    "        self.log(\"train/mA\", self.train_mA, prog_bar=True)\n",
    "        self.log(\"step\", self.current_epoch)\n",
    "        self.save_metrics()\n",
    "\n",
    "    def validation_step(self, batch, *args, **kwargs):\n",
    "        data, target, img_paths = batch\n",
    "        logits = self(data)\n",
    "        loss = self.loss_fn(logits, target)\n",
    "\n",
    "        self.mean_valid_loss.update(loss, weight=data.shape[0])\n",
    "        self.mean_valid_f1.update(logits, target)\n",
    "        self.valid_mA.update(logits, target)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Computing and logging the validation mean loss & mean f1.\n",
    "        self.log(\"valid/loss\", self.mean_valid_loss, prog_bar=True)\n",
    "        self.log(\"valid/f1\", self.mean_valid_f1, prog_bar=True)\n",
    "        self.log(\"valid/mA\", self.valid_mA, prog_bar=True)\n",
    "        self.log(\"step\", self.current_epoch)\n",
    "        self.save_metrics()\n",
    "\n",
    "        # Save predictions to file\n",
    "        self.save_predictions()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = getattr(torch.optim, self.hparams.optimizer_name)(\n",
    "            filter(lambda p: p.requires_grad, self.model.parameters()),\n",
    "            lr=self.hparams.init_lr,\n",
    "            weight_decay=self.hparams.weight_decay,\n",
    "        )\n",
    " \n",
    "        if self.hparams.use_scheduler:\n",
    "            lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "                optimizer,\n",
    "                milestones=[self.trainer.max_epochs // 2,],\n",
    "                gamma=0.1,\n",
    "            )\n",
    " \n",
    "            # The lr_scheduler_config is a dictionary that contains the scheduler\n",
    "            # and its associated configuration.\n",
    "            lr_scheduler_config = {\n",
    "                \"scheduler\": lr_scheduler,\n",
    "                \"interval\": \"epoch\",\n",
    "                \"name\": \"multi_step_lr\",\n",
    "            }\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler_config}\n",
    " \n",
    "        else:\n",
    "            return optimizer\n",
    "\n",
    "    def save_metrics(self):\n",
    "        metrics = {\n",
    "            \"epoch\": self.current_epoch,\n",
    "            \"train_loss\": self.mean_train_loss.compute().item(),\n",
    "            \"train_f1\": self.mean_train_f1.compute().item(),\n",
    "            \"train_mA\": self.train_mA.compute().item(),\n",
    "            \"valid_loss\": self.mean_valid_loss.compute().item(),\n",
    "            \"valid_f1\": self.mean_valid_f1.compute().item(),\n",
    "            \"valid_mA\": self.valid_mA.compute().item()\n",
    "        }\n",
    "        with open(self.metrics_file_path, \"a\") as f:\n",
    "            json.dump(metrics, f)\n",
    "            f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89435b7b-342b-4a0f-b833-be4a0f806507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "@torch.inference_mode()\n",
    "def predict_prob(input_image_paths, model=None, preprocess_fn=None, device=\"cpu\", idx2labels=None, output_csv=\"prob_predictions.csv\"):\n",
    "    predictions = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Create a tqdm progress bar\n",
    "    progress_bar = tqdm(input_image_paths, desc=\"Predicting\", unit=\"image\")\n",
    "\n",
    "    for image_path in progress_bar:\n",
    "        input_image = Image.open(image_path).convert(\"RGB\")\n",
    "        input_tensor = preprocess_fn(input_image)\n",
    "        input_tensor = input_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "        # Generate predictions\n",
    "        output = model(input_tensor).cpu()\n",
    "\n",
    "        probabilities = torch.sigmoid(output)[0].numpy().tolist()\n",
    "\n",
    "        predictions.append([image_path] + probabilities)\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    print(f\"Total prediction time: {total_time:.2f} seconds\")\n",
    "\n",
    "    # Write predictions to CSV file\n",
    "    with open(output_csv, \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"image\"] + list(idx2labels.values()))\n",
    "        for prediction in predictions:\n",
    "            writer.writerow(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "351c430d-c25c-43df-8f10-197b4976808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2labels = {\n",
    "     0: 'ethnicity_Caucasoid',\n",
    "     1: 'ethnicity_Mongoloid',\n",
    "     2: 'ethnicity_Negroid',\n",
    "     3: 'ethnicity_Unsure',\n",
    "     4: 'age_Adult',\n",
    "     5: 'age_Old',\n",
    "     6: 'age_Young',\n",
    "     7: 'gender_Female',\n",
    "     8: 'gender_Male',\n",
    "     9: 'hair_length_Bald',\n",
    "     10: 'hair_length_Long',\n",
    "     11: 'hair_length_Short',\n",
    "     12: 'upper_body_length_Long',\n",
    "     13: 'upper_body_length_Short',\n",
    "     14: 'upper_body_color_Black',\n",
    "     15: 'upper_body_color_Blue',\n",
    "     16: 'upper_body_color_Brown',\n",
    "     17: 'upper_body_color_Green',\n",
    "     18: 'upper_body_color_Grey',\n",
    "     19: 'upper_body_color_Orange',\n",
    "     20: 'upper_body_color_Other',\n",
    "     21: 'upper_body_color_Pink',\n",
    "     22: 'upper_body_color_Purple',\n",
    "     23: 'upper_body_color_Red',\n",
    "     24: 'upper_body_color_White',\n",
    "     25: 'upper_body_color_Yellow',\n",
    "     26: 'upper_body_type_Blouse',\n",
    "     27: 'upper_body_type_Dress',\n",
    "     28: 'upper_body_type_Jacket',\n",
    "     29: 'upper_body_type_Other',\n",
    "     30: 'upper_body_type_Polo',\n",
    "     31: 'upper_body_type_Shirt',\n",
    "     32: 'upper_body_type_Tanktop',\n",
    "     33: 'upper_body_type_Tshirt',\n",
    "     34: 'lower_body_length_Long',\n",
    "     35: 'lower_body_length_Short',\n",
    "     36: 'lower_body_color_Black',\n",
    "     37: 'lower_body_color_Blue',\n",
    "     38: 'lower_body_color_Brown',\n",
    "     39: 'lower_body_color_Green',\n",
    "     40: 'lower_body_color_Grey',\n",
    "     41: 'lower_body_color_Orange',\n",
    "     42: 'lower_body_color_Other',\n",
    "     43: 'lower_body_color_Pink',\n",
    "     44: 'lower_body_color_Purple',\n",
    "     45: 'lower_body_color_Red',\n",
    "     46: 'lower_body_color_White',\n",
    "     47: 'lower_body_color_Yellow',\n",
    "     48: 'lower_body_type_Skirt&Dress',\n",
    "     49: 'lower_body_type_Trousers&Shorts',\n",
    "     50: 'footwear_Sandals',\n",
    "     51: 'footwear_Shoes',\n",
    "     52: 'backpack_Yes',\n",
    "     53: 'bag_Yes',\n",
    "     54: 'glasses_No',\n",
    "     55: 'glasses_Normal',\n",
    "     56: 'glasses_Sun',\n",
    "     57: 'hat_Yes',\n",
    "     58: 'mask_Yes'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5336145f-6286-4da5-8ac2-60c84fa1af1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|███████████████████████| 2437/2437 [00:06<00:00, 373.11image/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total prediction time: 6.53 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# Define the path to your .pth file\n",
    "model_path = f\"./{TrainingConfig.MODEL_NAME}_1.pth\"\n",
    "\n",
    "model = torch.load(model_path, map_location=DEVICE)\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "preprocess = TF.Compose(\n",
    "        [\n",
    "            TF.Resize(size=DatasetConfig.IMAGE_SIZE[::-1]),\n",
    "            TF.ToTensor(),\n",
    "            TF.Normalize(DatasetConfig.MEAN, DatasetConfig.STD, inplace=True),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "annotation_path = '/home/noeyiue/cpe/ICSEC/annotation/test_data.csv'\n",
    "test_data = pd.read_csv(annotation_path, index_col=0)\n",
    "test_img_ids = test_data.index\n",
    "\n",
    "IMG_DIR: str = \"/home/noeyiue/cpe/ICSEC/annotation/dataset\"\n",
    "# Prepare input image paths\n",
    "input_image_paths = [os.path.join(IMG_DIR, img_id ) for img_id in test_img_ids]\n",
    "\n",
    "# Perform predictions and save to CSV\n",
    "predict_prob(input_image_paths, model=model, preprocess_fn=preprocess, idx2labels=idx2labels, device=DEVICE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2a8d14-f473-4550-9271-fa0fb392a78d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
